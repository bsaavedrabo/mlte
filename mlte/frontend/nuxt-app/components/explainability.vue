<template>
  <div>
    <br />
    <!-- API call -->
    <div class="chatgptcall">
      <p>
        Explainability refers to the ability to describe the decisions of a machine learning model in a way that is understandable to the end users.
        <span class="AIgeneratedtext">{{ response }} </span>
      </p>
    </div>
    <br />

    <div>
      <!-- 1) Stakeholders List -->
      <label><b>Stakeholder or Recipient of the explanation</b></label>
      <!-- <div class="info-container">
        <span class="info-icon">i</span>
        <div class="tooltip">API call for project-specific definition</div>
      </div> -->
      <!-- USelect Component -->
      <USelect
        placeholder="Select an option..."
        icon="i-heroicons-magnifying-glass-20-solid"
        v-model="stakeholder"
        :options="stakeholder_list"
      />

      <!-- Conditionally show input field for 'Other' -->
      <br />
      <div v-if="showOtherInput">
        <label for="otherInput"><b>*Specify Other Stakeholder</b> </label>
        <UInput v-model="OtherStakeholder" style="width: 300px;" />
        <br />
      </div>

      <!-- 2) Purpose -->
      <label><b>Purpose of the Explanations</b></label>
      <div class="info-container">
        <span class="info-icon">i</span>
        <div class="tooltip">API call for project-specific definition</div>
      </div>

      <USelect
        placeholder="Select an option..."
        icon="i-heroicons-magnifying-glass-20-solid"
        v-model="purpose"
        :options="purpose_list"
      />
      <br />

         <!-- Foresee challenges achieving explanation expectations -->
         <label><b>Foreseeable Consequences of not considering Explainability</b></label>
      <div class="info-container">
        <span class="info-icon">i</span>
        <div class="tooltip">  </div>
      </div>
      <UInput size="sm" v-model="consequences" />
      <br />


       <!-- Foresee challenges achieving explanation expectations -->
       <label><b>Foreseeable Challenges in Meeting Explainability Expectations</b></label>
      <div class="info-container">
        <span class="info-icon">i</span>
        <div class="tooltip">Expand on what challenges you may encounter </div>
      </div>
      <UInput size="sm" v-model="sourceofexplanation" />
      <br />

        <!-- 4) Type of Explanations -->
        <label><b>Type of Explanation</b></label>
      <div class="info-container">
        <span class="info-icon">i</span>
        <div class="tooltip">API call for project-specific definition</div>
      </div>

      <!-- USelectMenu with multiple selection enabled -->
      <USelect
        v-model="ExplanationType"
        :options="explainabilityType"
        placeholder="Select options..."
      />

      <br />
      <!-- 3) Language level  -->
      <label><b>Language Level Expectations</b></label>
      <div class="info-container">
        <span class="info-icon">i</span>
        <div class="tooltip">API call for project-specific definition</div>
      </div>
      <UInput size="sm" v-model="language_level" />
      <br />

    

      <!-- Test Plan -->
      <label><b>Success Criteria</b></label>
      <div class="info-container">
        <span class="info-icon">i</span>
        <div class="tooltip">API call for project-specific definition</div>
      </div>
      <UInput size="sm" v-model="sourceofexplanation" />
      <br />

     

      <!-- Dynamic Sentence -->
      <p class="input-group" style="padding-top: 10px; padding-bottom: 10px">
        <b>Scenario for Explainability:</b> [{{ selectedStakeholderLabel }}] require explanation(s) from [{{ sourceofexplanation }}] on [{{ aspects }}] when [{{ scenarios }}]. [{{ limitations }}] may make it challenging to provide the required explanations.
      </p>

      <span class="AIgeneratedtext" id="cautiontext"> Highlighted text was generated by AI. Verify information as ChatGPT can make mistakes</span>
    </div>
  </div>


  <div>
              <UTable :rows="tableData" :columns="columns" >
                  <!-- <template #body-cell="{ item, column, rowIndex}"> -->
                  <template #pert-data="{ row, column }">
                      <UInput v-model="row.name" placeholder="Add Perturbation"/>
                  </template>

                  <template #tolerance-data="{ row, column }">
                      <UInput v-model="row.email" placeholder="Add Tolerance Level"/>
                  </template>
              </UTable>
          </div>

          <div>
              <UButton color="yellow" :ui="{ rounded: 'rounded-full' }" @click="addRow">+</UButton>
              <UButton color="yellow" :ui="{ rounded: 'rounded-full' }" @click="removeRow" :disabled="tableData.length === 0">-</UButton>
          </div>

          
  <p> </p>
</template>

<script lang="ts">
import { ref, onMounted, computed, watch } from 'vue';
import { openai } from '~/composables/openai';

export default {
  data() {
    return {
      // List of options for explanation types
      explainabilityType: [
        'Global Explanations (explain how the model works)',
        'Local Explanations (explain individual predictions)',
      ],
      // Placeholder for storing selected explanation types
      ExplanationType: [] as string[], 
    };
  },

  name: 'InferenceLatencyForm',
  props: {
    MLTask: {
      required: true,
    },
    usageContext: {
      required: true,
    },
  },
  setup(props) {

    // Define variables related to the table
    const columns = ref([
              { key: 'pert', label: 'Perturbations' },
              { key: 'tolerance', label: 'Tolerance Level' },
          ]);

          const tableData = ref([
              { pert: '', tolerance: '' },
          ]);

          const addRow = () => {
              tableData.value.push({ pert: '', tolerance: '' });
          };

          const removeRow = () => {
              if (tableData.value.length > 0) {
                  tableData.value.pop();
              }
          };

    const response = ref('');
    const stakeholder = ref('');
    const stakeholder_list = ref([]);
    const purpose= ref([]);
    const purpose_list= ref([]);
    const OtherStakeholder = ref('');
    const showOtherInput = ref(false); 

    const selectedStakeholderLabel = computed(() => {
      const selected = stakeholder_list.value.find(item => item.value === stakeholder.value);
      return selected ? selected.label : ''; // Return the label if found
    });

    // Handle the selection of the "Other" option
    const handleSelection = () => {
      showOtherInput.value = stakeholder.value === 'stakeholder_other';
    };

    // Watch the stakeholder value to trigger the handleSelection function
    watch(stakeholder, handleSelection);

    const chat_role = 'You are a specialized data scientist with knowledge in both software engineering and data science. Offer thoughtful insights.';

    const getChatResponse = async () => {
      const { chat } = openai();
      try {
        const messages = [
          {
            role: 'system',
            content: chat_role,
          },
          {
            role: 'user',
            content: `Write one sentence to explain the potential consequences of not considering proper explainability in the context of ${props.MLTask} and ${props.usageContext}. 
            Describe why explainability is essential for different levels and stakeholders. Provide concrete examples. Explainability can be used for the following purposes: 
            Dignity, Transparency for accountability, Legal compliance, Bias detection, risk assessment, Model/System Debugging, Model evaluation, Actionable insights
            Stakeholder trust, Documentation, Informed decision-making, User Autonomy. Use language targeted for data scientists.`,
          },
        ];

        const chatResponse = await chat(messages, 'gpt-3.5-turbo');
        const splitResponse = chatResponse.split('\n\n');
        response.value = splitResponse[0];
        console.log('API response:', response.value);
      } catch (error) {
        console.error('Error fetching chat response:', error);
      }
    };

    // SECOND CALL 
    const GetStakeholders = async () => {
      const { chat } = openai();
      try {
        const messages = [
          {
            role: 'system',
            content: 'You are a product manager with experience in bringing together different non-technical and technical stakeholders for including potential users of the product. You have experience managing AI products',
          },
          {
            role: 'user',
            content: `Provide a list of specific potential technical and non-technical stakeholders for a ${props.MLTask} model and the context use is ${props.usageContext}. Do not number the list. Do not include subtitles.`,
          },
        ];

        const chatStakeholders = await chat(messages, 'gpt-3.5-turbo');

        const stakeholdersArray = chatStakeholders
          .split('\n')
          .filter(stakeholder => stakeholder.trim() !== '') // Filter out empty lines
          .map((stakeholder, index) => ({
            label: stakeholder.replace(/^-/, '').trim(),
            value: `stakeholder_${index}`,
          }));

        stakeholder_list.value = stakeholdersArray;
        stakeholder_list.value.push({ label: 'Other', value: 'stakeholder_other' });
      } catch (error) {
        console.error('Error fetching chat response for stakeholders:', error);
      }
    };

    // THIRD CALL

    const GetPurpose = async () => {
  const { chat } = openai();
  try {
    const messages = [
      {
        role: 'system',
        content: 'You are a product manager with experience in bringing together different non-technical and technical stakeholders for including potential users of the product. You have experience managing AI products',
      },
      {
        role: 'user',
        content: `Provide a list of purposes a ${selectedStakeholderLabel} would care about Explainability for a ${props.MLTask} model and the context use is ${props.usageContext}. Do not number the list. Do not include subtitles. Do not include descriptions of each purpose.`,
      },
    ];

    const chatPurpose = await chat(messages, 'gpt-3.5-turbo');

    const PurposeArray = chatPurpose
      .split('\n')
      .filter(purpose => purpose.trim() !== '') // Filter out empty lines
      .map((purpose, index) => ({
        label: purpose.replace(/^-/, '').trim(),
        value: `purpose_${index}`,
      }));

    purpose_list.value = PurposeArray; // Use PurposeArray instead of stakeholdersArray
    purpose_list.value.push({ label: 'Other', value: 'purpose_other' });
  } catch (error) {
    console.error('Error fetching chat response for purpose:', error);
  }
};


    onMounted(() => {
      getChatResponse();
      GetStakeholders();
      GetPurpose();
    });

    return {
      response,
      stakeholder,
      stakeholder_list,
      purpose_list,
      purpose,
      showOtherInput, 
      OtherStakeholder,
    };
  },
};
</script>

<style scoped>
.AIgeneratedtext {
  background-color: #efe8c7;
}

.info-icon {
  display: inline-block;
  width: 20px;
  height: 20px;
  background-color: black;
  color: white;
  border-radius: 50%;
  text-align: center;
  line-height: 20px;
  font-weight: bold;
  font-family: Arial, cursive;
  font-size: 10px;
  cursor: pointer;
  margin-left: 5px;
  position: relative;
}

.tooltip {
  display: none;
  position: absolute;
  background-color: rgb(0, 0, 0);
  color: rgb(255, 255, 255);
  border: 1px solid #ccc;
  padding: 10px;
  font-size: 12px;
  border-radius: 5px;
  box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
  width: 200px;
  top: 25px;
  left: 0;
  z-index: 10;
}

.info-container:hover .tooltip {
  display: block;
}

.info-container {
  position: relative;
  display: inline-block;
}
</style>
