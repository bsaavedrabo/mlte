<template>
  <div>
    <br />
    <!-- API call -->
    <div class="chatgptcall">
      <p>
        Also known as learning time, refers to the time taken for a model to process training data.
        <span class="AIgeneratedtext">{{ response }} </span>
      </p>
    </div>

    <!-- <p> <b>What does that mean for your project?</b></p> -->
     <br/>
    <p><b>Background Questions </b></p>
    <br/>
<div>  
  <!-- 1  Option -->
  <label><b>Select the retraining method you will use for your model</b></label>

  <div class="info-container">
    <span class="info-icon">i</span>
    <div class="tooltip">API call for project-specific definition</div>
  </div>

  <!-- USelect Component -->
  <USelect
    placeholder="Select an option..."
    :options="retrainingmethodslist"
    icon="i-heroicons-magnifying-glass-20-solid"
    v-model="retrainingMethod"
    @change="handleSelection"
  />

  <!-- Conditionally show input field for 'Other' -->
  
  <div v-if="showOtherInput">
    <label for="otherInput"><b>*Specify Training Location</b> </label>
    <UInput v-model="OtherRetrainingOption" placeholder="Specify your training option" style="width: 300px;" />
  </div>

  <br/>

  <label><b> Source of the data for retraining </b></label>
    <div class="info-container">
      <span class="info-icon">i</span>
      <div class="tooltip">API call for project-specific definition</div>
    </div>
    <UInput v-model="DataSource" />
    <br/>

  <div>
    <!-- Deployment Infrastructure -->
    <label><b> Frequency of Retraining </b></label>
    <div class="info-container">
      <span class="info-icon">i</span>
      <div class="tooltip">API call for project-specific definition</div>
    </div>

    <!-- Deployment Infrastructure Selection -->
    <USelect
      placeholder="Select an option..."
      :options="secondoptions"
      icon="i-heroicons-magnifying-glass-20-solid"
      v-model="infrastructureDetails"
      @change="handleSelectionDeployment"
     
    />

    <!-- Conditionally show input field for Other -->
    <div v-if="showOtherInputDeployment">
      <label for="otherInput"><b>*Specify Other Training Method</b></label>
      <UInput v-model="OtherDeploymentOption" placeholder="Specify your deployment infrastructure" style="width: 300px;" />
    </div>
    <br/>
  </div>
  
 

  <p><b>Requirement</b></p>
    <br/>


    <!-- -->

    <label><b>Expected Retraining Latency</b></label>

    <div class="info-container">
      <span class="info-icon">i</span>
      <div class="tooltip">{{ExpectedLatencyResponse}}</div>
    </div>

    <div style="display: flex; align-items: center;"> 
    <UInput 
    v-model="ExpectedLatency" 
    style="width: 50px;" 
     />
     <p style="margin-left:8px; margin-bottom:0;">

    <USelect
          placeholder="unit"
          variant="outline"
          :options="['secs', 'mins', 'hours']"
           v-model="unit_averagelatency"
      />
      </p>
     </div>
    <br />

      <!-- Dynamic Sentence -->
      <p class="input-group" style="padding-top: 10px; padding-bottom: 10px">
  <b>Scenario for Training Latency:</b> The model's retraining latency is expected to be [{{ ExpectedLatency }}] {{unit_averagelatency}} using [{{ retrainingMethod }}]. The source of the retraining data is from [{{ DataSource }}].
</p>
<br/>
<UButton color="yellow" :ui="{ rounded: 'rounded-full' }" @click="checkMetrics" :style="{color: 'black'}" ><b>Do these metrics make sense?</b></UButton>

<br/>
<br/>

<!-- Display the 2nd call -->

<p v-if="secondResponse && secondResponse.length > 0">
    <span class="AIgeneratedtext">
        <ul>
            <li v-for="(bullet, index) in secondResponse" :key="index" class="spaced-bullet">{{ bullet }}</li>
        </ul>
    </span>
</p>


<br/>
</div>
</div>


<!-- SAVE BUTTON --> 
<div style="display: flex; align-items: center;">
    <UButton color="yellow" :disabled="!isFormComplete" @click="saveForm" :style="{color: 'black', width: '80px', justifyContent: 'center', alignItems: 'center'}">
        <b>Save</b>
    </UButton>
    <p v-if="saveStatusMessage" style="color: gray; margin-left: 10px; font-size: 14px;">
        {{ saveStatusMessage }}
    </p>
</div>

<br/>

<span class="AIgeneratedtext" id="cautiontext"> Highlighted text was generated by AI. Verify information as ChatGPT can make mistakes </span>


<p> </p>

</template>

<script lang="ts">
import type { _textColor } from '#tailwind-config/theme';
import { ref, onMounted, computed } from 'vue';
import { openai } from '~/composables/openai';

export default {
  data() {
    return {
      selectedOption: '',
      otherOptionValue: '',
      showOtherOption: false,
      OtherDeploymentOption: '',
      infrastructureDetails: '', 
      retrainingMethod: '', 
      otherInputValue: '', 
      showOtherInput: false, 
      showOtherInputDeployment: false,
      secondoptions: [
        'Real-time (as new data arrives)', 
        'Trigger-based',
        'Daily', 
        'Weekly', 
        'Monthly',
        'TBD', 
        'Other'
      ],

      retrainingmethodslist: [
        'Incremental learning',
        'Batch learning',
        'TBD',
        'Other',
        ],
  
    };
  },

  // METHODS 
  methods: {
    toggleOtherOption() {
      this.showOtherOption = this.selectedOption === 'other';
    },
    handleSelection() {
      // Show the input field if "Other" is selected
      this.showOtherInput = this.retrainingMethod
 === 'Other';
    },

    handleSelectionDeployment(){
      this.showOtherInputDeployment = this.infrastructureDetails === 'Other';
    }

  },

  // COMPONENT METADATA
  name: 'InferenceLatencyForm',
  props: {
    MLTask: {
      required: true,
    },
    usageContext: {
      required: true,
    },
  },

  // SETUP 
  setup(props) {
    const response = ref('');
    const secondResponse = ref('');
    const retrainingMethod = ref<string | null>(null);
    const ExpectedLatencyResponse = ref<string | null>(null);
    const DataSource = ref<string | null>(null);
    const unit_averagelatency = ref<string | null>(null);
    const OtherRetrainingOption = ref<string | null>(null);
    const infrastructureDetails = ref<string | null>(null);
    const ExpectedLatency = ref<string | null>(null);
    const PercentageLatency = ref<string | null>(null);
    const latencySeconds = ref<string | null>(null);

    // New state for save status
    const saveStatusMessage = ref('');

    // Computed property to check if the form is complete
    const isFormComplete = computed(() => {
        return (
            retrainingMethod
      .value &&
            infrastructureDetails.value &&
            ExpectedLatency.value &&
            PercentageLatency.value &&
            latencySeconds.value
        );
    });

    const saveForm = () => {
        // Here you can save the data. This is a simple example.
        const formData = {
            retrainingMethod
      : retrainingMethod
      .value,
            infrastructureDetails: infrastructureDetails.value,
            ExpectedLatency: ExpectedLatency.value,
            PercentageLatency: PercentageLatency.value,
            latencySeconds: latencySeconds.value,
        };
         // Save to local storage
        localStorage.setItem('formData', JSON.stringify(formData));
        // Simulate saving the data (e.g., make an API call)
      
        console.log("Saving form data:", formData);
        
        saveStatusMessage.value = "Form saved successfully";


    };

    const firstWordOfDeploymentInfrastructure = computed(() => {
      if (retrainingMethod
.value) {
        return retrainingMethod
  .value.split(' ')[0]; 
      }
      return '';
    });

    const firstWordOfinfrastructureDetails = computed(() => {
      if (infrastructureDetails.value) {
        return infrastructureDetails.value.split(' ')[0]; 
      }
      return '';
    });

    // OPEN AI API INTEGRATION

    // Consequence call 
    const chat_role = 'You are a specialized data scientist with knowledge in both software engineering and data science. Offer thoughful criticism.';

    const getChatResponse = async () => {
      const { chat } = openai();
      try {
        const messages = [
          {
            role: 'system',
            content: chat_role,
          },
          {
            role: 'user',
            content: `Write one sentence to explain the potential consequences of not considering training latency in the context of ${props.MLTask} and ${props.usageContext}. Use language that data scientists would understand.
            Provide a realistic consequences and focus on retraining latency.`,
          },
        ];

        const chatResponse = await chat(messages, 'gpt-3.5-turbo');
        const splitResponse = chatResponse.split('\n\n');
        response.value = splitResponse[0];
      } catch (error) {
        console.error('Error fetching chat response:', error);
      }
    };


    // Evaluation button 
    const checkMetrics = async () => {
    const { chat } = openai();
    try {
        const messages = [
            {
                role: 'system',
                content: chat_role,
            },
            {
                role: 'user',
                content: `Please review the following latency metrics for ${props.MLTask}:
                - Average Latency: ${ExpectedLatency.value} seconds
                - Percentage of Requests to Meet Target: ${PercentageLatency.value}% requests should meet this latency
                - Latency in Seconds: ${latencySeconds.value} seconds
                - The Inference option for this project is ${retrainingMethod
          .value}
                - The deployment infrastructure for this project is ${infrastructureDetails.value}


                Do these metrics seem reasonable for this project? Please respond with three brief bullet points:
                - [check mark or caution emoji] Maximum Expected retraining latency: 
                if the answer is reasonable, then provide a green check mark emoji. If the answer is not reasonable or changes are suggested, provide a waning emoji in the [emoji] space.
    
                Consider that data scientists may have the following misconceptions: 
                - Data scientists might focus only on optimizing the model to reduce latency, overlooking other sources of high latency 
                such as data preprocessing, feature extraction, or system integration.
                - Data scientists might not understand how high inference latency affects user experience which can lead to dissatisfaction and reduced user engagement
                - Data scientists might not be aware of the impact of model size on latency, where larger models typically require more processing time.
                `
    
                ,
            },
        ];

        const chatResponse = await chat(messages, 'gpt-3.5-turbo');
        
        // Clean the chat response and extract the bullet points
        secondResponse.value = formatSecondResponse(chatResponse);
    } catch (error) {
        console.error('Error fetching metrics response:', error);
    }
};

// Function to format the second API response
function formatSecondResponse(text) {
    // Split the response into lines and filter out empty lines
    const lines = text.split('\n').filter(line => line.trim() !== '');
    
    // Map lines to create a bullet point list and return only the first three items
    const bullets = lines.slice(0, 3).map(line => line.trim());
    
    // Return the formatted output
    return bullets;
}


    // HOOK
    onMounted(() => {
      getChatResponse(); // initial call 
        // Load data from local storage
        const storedData = localStorage.getItem('formData');
        if (storedData) {
        const formData = JSON.parse(storedData);
        retrainingMethod
  .value = formData.retrainingMethod
  ;
        infrastructureDetails.value = formData.infrastructureDetails;
        ExpectedLatency.value = formData.ExpectedLatency;
        PercentageLatency.value = formData.PercentageLatency;
        latencySeconds.value = formData.latencySeconds;
    }
    });

    return {
      response,
      secondResponse,
      retrainingMethod,
      DataSource,
      ExpectedLatencyResponse,
      OtherRetrainingOption,
      infrastructureDetails,
      ExpectedLatency,
      PercentageLatency,
      latencySeconds,
      firstWordOfDeploymentInfrastructure, 
      firstWordOfinfrastructureDetails,
      checkMetrics,
      //splitByDash,
      saveStatusMessage,   
      isFormComplete,      
      saveForm,  
    };
  },
};
</script>


<style scoped>
.AIgeneratedtext{
  background-color: #efe8c7;
}

.info-icon {
  display: inline-block;
  width: 20px;
  height: 20px;
  background-color: black;
  color: white;
  border-radius: 50%;
  text-align: center;
  line-height: 20px;
  font-weight: bold;
  font-family: Arial, cursive;
  font-size: 10px;
  cursor: pointer;
  margin-left: 5px;
  position: relative;
}

.tooltip {
  display: none;
  position: absolute;
  background-color: rgb(0, 0, 0);
  color: rgb(255, 255, 255);
  border: 1px solid #ccc;
  padding: 10px;
  font-size: 12px;
  border-radius: 5px;
  box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
  width: 200px;
  top: 25px; 
  left: 0;
  z-index: 10;
}

.info-container:hover .tooltip {
  display: block;
}

.info-container {
  position: relative;
  display: inline-block;
}

#cautiontext{
  font-size: 12px;
  font-style: italic;
  text-align: center;
}
.spaced-bullet {
  margin-bottom: 10px; 
}
.highlighted-bullet {
  background-color: #f0f8ff; 
  padding: 10px;           
  border-radius: 5px;        
  margin-bottom: 10px;      
  font-weight: bold;       
  color: #333;             
  box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.1); 
}
</style>