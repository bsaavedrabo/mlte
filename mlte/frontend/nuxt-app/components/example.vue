<template>
    <div>
      <br />
      <!-- API call -->
      <div class="chatgptcall">
        <p>
          Explainability refers to the ability to describe the decisions of a machine learning model in a way that is understandable to the end users.
          <span class="AIgeneratedtext">{{ response }} </span>
        </p>
      </div>
      <br />
  
      <div>
        <!-- 1) Stakeholders List -->
        <label><b>Stakeholder or Recipient</b></label>
        <!-- <div class="info-container">
          <span class="info-icon">i</span>
          <div class="tooltip">API call for project-specific definition</div>
        </div> -->
        <!-- USelect Component -->
        <USelect
          placeholder="Select an option..."
          icon="i-heroicons-magnifying-glass-20-solid"
          v-model="stakeholder"
          :options="stakeholder_list"
        />
  
        <!-- Conditionally show input field for 'Other' -->
        <br />
        <div v-if="showOtherInput">
          <label for="otherInput"><b>*Specify Other Stakeholder</b> </label>
          <UInput v-model="OtherStakeholder" style="width: 300px;" />
          <br />
        </div>
  
        <!-- 2) Purpose -->
        <label><b>Purpose of the Explanations</b></label>
        <div class="info-container">
          <span class="info-icon">i</span>
          <div class="tooltip"> </div>
        </div>
  
        <USelect
          placeholder="Select an option..."
          icon="i-heroicons-magnifying-glass-20-solid"
          v-model="purpose"
          :options="purpose_list"
        />
        
   
  
           <!-- Foresee challenges achieving explanation expectations -->
           <label><b>Anticipated Consequences of Neglecting Explainability</b></label>
        <div class="info-container">
          <span class="info-icon">i</span>
          <div class="tooltip">  </div>
        </div>
        <UInput size="sm" v-model="consequences" />
        <br />
  
  
         <!-- Foresee challenges achieving explanation expectations -->
         <label><b> Anticipated Challenges to Achieve Explainability Expectations</b></label>
        <div class="info-container">
          <span class="info-icon">i</span>
          <div class="tooltip">Expand on what challenges you may encounter </div>
        </div>
        <UInput size="sm" v-model="sourceofexplanation" />
        <br />
  
          <!-- 4) Type of Explanations -->
          <label><b>Type of Explanations</b></label>
        <div class="info-container">
          <span class="info-icon">i</span>
          <div class="tooltip">API call for project-specific definition</div>
        </div>
  
        <!-- USelectMenu with multiple selection enabled -->
        <USelect
          v-model="ExplanationType"
          :options="explainabilityType"
          placeholder="Select options..."
        />
  
        <br />
        <!-- 3) Language level  -->
        <label><b>Understandability Expectations</b></label>
        <div class="info-container">
          <span class="info-icon">i</span>
          <div class="tooltip">API call for project-specific definition</div>
        </div>
        <UInput size="sm" v-model="language_level" />
        <br />
  
      
  
        <!-- Test Plan -->
        <label><b>Success Criteria</b></label>
        <div class="info-container">
          <span class="info-icon">i</span>
          <div class="tooltip">API call for project-specific definition</div>
        </div>
        <UInput size="sm" v-model="sourceofexplanation" />
        <br />
  
       
  
        <!-- Dynamic Sentence -->
        <p class="input-group" style="padding-top: 10px; padding-bottom: 10px">
          <b>Scenario for Explainability:</b> [{{ selectedStakeholderLabel }}] require explanation(s) from [{{ sourceofexplanation }}] on [{{ aspects }}] when [{{ scenarios }}]. [{{ limitations }}] may make it challenging to provide the required explanations.
        </p>
  
        <span class="AIgeneratedtext" id="cautiontext"> Highlighted text was generated by AI. Verify information as ChatGPT can make mistakes</span>
      </div>
    </div>
  
    <p> </p>
  </template>
  
  <script lang="ts">
  import { ref, onMounted, computed, watch } from 'vue';
  import { openai } from '~/composables/openai';
  
  export default {
    data() {
      return {
        // List of options for explanation types
        explainabilityType: [
          'Global Explanations (explain how the model works)',
          'Local Explanations (explain individual predictions)',
          'Data Disclosure', 
          'Counterfactual Instances(local)',
          'Visualizations',
          'Surrogate models that are inherently explainable',
          'Explainable Boosting Machine (local and global)',
          'Other'
        ],
        // Placeholder for storing selected explanation types
        ExplanationType: [] as string[], 
      };
    },
  
    name: 'InferenceLatencyForm',
    props: {
      MLTask: {
        required: true,
      },
      usageContext: {
        required: true,
      },
    },
    setup(props) {
  
      // Define variables related to the table
      const columns = ref([
    { key: 'stak', label: 'Stakeholder' },
    { key: 'pur', label: 'Purpose' },
    { key: 'conseq', label: 'Consequences' },
  ]);
  
            const tableData = ref([
                { stak: '', pur: '', conseq:'' },
            ]);
  
            const addRow = () => {
    tableData.value.push({ stak: '', pur: '', conseq: '' }); 
  };
  
  const removeRow = () => {
    if (tableData.value.length > 0) {
      tableData.value.pop(); // Removing a row
    }
  };
  
      const response = ref('');
      const stakeholder = ref('');
      const stakeholder_list = ref([]);
      const purpose= ref([]);
      const purpose_list= ref([]);
      const OtherStakeholder = ref('');
      const showOtherInput = ref(false); 
  
      const selectedStakeholderLabel = computed(() => {
        const selected = stakeholder_list.value.find(item => item.value === stakeholder.value);
        return selected ? selected.label : ''; // Return the label if found
      });
  
      // Handle the selection of the "Other" option
      const handleSelection = () => {
        showOtherInput.value = stakeholder.value === 'stakeholder_other';
      };
  
      // Watch the stakeholder value to trigger the handleSelection function
      watch(stakeholder, handleSelection);
  
      const chat_role = 'You are a specialized data scientist with knowledge in both software engineering and data science. Offer thoughtful insights.';
  
      const getChatResponse = async () => {
        const { chat } = openai();
        try {
          const messages = [
            {
              role: 'system',
              content: chat_role,
            },
            {
              role: 'user',
              content: `Write a concise sentence explaining a potential consequence of neglecting proper explainability in the context of
               ${props.MLTask} and ${props.usageContext} for a non-technical stakeholder of the product. 
  
              Focus on one of the following purposes for explainability:
              Human-AI collaboration
              Oversight
              Dignity/Autonomy
  
              Choose one of the purposes listed above to explain why explainability is critical for a non-technical stakeholder. 
              Provide a brief and concrete example. Use precise and targeted language for data scientists. Do not mention the term trust.`,
            },
          ];
  
          const chatResponse = await chat(messages, 'gpt-3.5-turbo');
          const splitResponse = chatResponse.split('\n\n');
          response.value = splitResponse[0];
          console.log('API response:', response.value);
        } catch (error) {
          console.error('Error fetching chat response:', error);
        }
      };
  
      // SECOND CALL 
      const GetStakeholders = async () => {
        const { chat } = openai();
        try {
          const messages = [
            {
              role: 'system',
              content: 'You are a product manager with experience in bringing together different non-technical and technical stakeholders for including potential users of the product. You have experience managing AI products',
            },
            {
              role: 'user',
              content: `Provide a list of specific potential technical and non-technical stakeholders for a ${props.MLTask} model and the context use is ${props.usageContext}. Do not number the list. Do not include subtitles.`,
            },
          ];
  
          const chatStakeholders = await chat(messages, 'gpt-3.5-turbo');
  
          const stakeholdersArray = chatStakeholders
            .split('\n')
            .filter(stakeholder => stakeholder.trim() !== '') // Filter out empty lines
            .map((stakeholder, index) => ({
              label: stakeholder.replace(/^-/, '').trim(),
              value: `stakeholder_${index}`,
            }));
  
          stakeholder_list.value = stakeholdersArray;
          stakeholder_list.value.push({ label: 'Other', value: 'stakeholder_other' });
        } catch (error) {
          console.error('Error fetching chat response for stakeholders:', error);
        }
      };
  
      // THIRD CALL
  
      const GetPurpose = async () => {
    const { chat } = openai();
    try {
      const messages = [
        {
          role: 'system',
          content: 'You are a product manager with experience in bringing together different non-technical and technical stakeholders for including potential users of the product. You have experience managing AI products',
        },
        {
          role: 'user',
          content: ` Generate a 5-word sentence description to the list of purposes provided below. Describe why botanists would be interested in an explanation of the ${props.MLTask} model with a context use of ${props.usageContext}.
          Dignity : [write reason why stakeholder selected cares about explanability]
          Transparency for accountability: [write reason why stakeholder selected cares about explanability]
          Legal compliance: [write reason why stakeholder selected cares about explanability]
          Bias detection: [write reason why stakeholder selected cares about explanability]
          Risk assessment: [write reason why stakeholder selected cares about explanability]
          Model/System Debugging: [write reason why stakeholder selected cares about explanability]
          Model evaluation: [write reason why stakeholder selected cares about explanability]
          Actionable insights: [write reason why stakeholder selected cares about explanability]
          Stakeholder trust: [write reason why stakeholder selected cares about explanability]
          Documentation: [write reason why stakeholder selected cares about explanability]
          Informed decision-making: [write reason why stakeholder selected cares about explanability]
          User Autonomy: [write reason why stakeholder selected cares about explanability]
  
          `,
        },
      ];
  
      const chatPurpose = await chat(messages, 'gpt-3.5-turbo');
  
      const PurposeArray = chatPurpose
        .split('\n')
        .filter(purpose => purpose.trim() !== '') // Filter out empty lines
        .map((purpose, index) => ({
          label: purpose.replace(/^-/, '').trim(),
          value: `purpose_${index}`,
        }));
  
      purpose_list.value = PurposeArray; // Use PurposeArray instead of stakeholdersArray
      purpose_list.value.push({ label: 'Other', value: 'purpose_other' });
    } catch (error) {
      console.error('Error fetching chat response for purpose:', error);
    }
  };
  
  
      onMounted(() => {
        getChatResponse();
        GetStakeholders();
        GetPurpose();
      });
  
      return {
        response,
        stakeholder,
        stakeholder_list,
        purpose_list,
        purpose,
        showOtherInput, 
        OtherStakeholder,
        addRow,
        removeRow,
        columns,
        tableData,
      };
    },
  };
  </script>
  
  <style scoped>
  .AIgeneratedtext {
    background-color: #efe8c7;
  }
  
  .info-icon {
    display: inline-block;
    width: 20px;
    height: 20px;
    background-color: black;
    color: white;
    border-radius: 50%;
    text-align: center;
    line-height: 20px;
    font-weight: bold;
    font-family: Arial, cursive;
    font-size: 10px;
    cursor: pointer;
    margin-left: 5px;
    position: relative;
  }
  
  .tooltip {
    display: none;
    position: absolute;
    background-color: rgb(0, 0, 0);
    color: rgb(255, 255, 255);
    border: 1px solid #ccc;
    padding: 10px;
    font-size: 12px;
    border-radius: 5px;
    box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
    width: 200px;
    top: 25px;
    left: 0;
    z-index: 10;
  }
  
  .info-container:hover .tooltip {
    display: block;
  }
  
  .info-container {
    position: relative;
    display: inline-block;
  }
  </style>